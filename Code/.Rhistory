#Code written by Ryan Oprea, edited by Uri SImonsohn
#2024 12 18
library('groundhog')
pkgs=c('this.path','magrittr','tibble','tidyverse','jsonlite')
date='2024-12-01'
groundhog.library(pkgs,date)
#Paths
RB=dirname(this.dir())
data_path=paste0(RB,"/data/")
other_path=paste0(RB,"/other/")
#datapaths
main = dirname(dirname(dirname(this.dir())))
data_path = paste0(main,"/Data/")
fp        = paste0(other_path,"error1_raw.csv")
D=read.csv(fp)
# Clean
D<-D[-(1:2),] #Remove junk row
S<-data.frame()
# Remove any corrupted records
D$clength<-nchar(D$dataSet)
D<-D[D$clength<50000,]
for(s in 1:length(unique(D$ID))){
x<-D[s,]$dataSet%>%
fromJSON()%>%
map_if(is.data.frame, list)%>%
as_tibble()
df<-x
df$ID<-D[s,]$ID
df$aveFirst<-D[s,]$aveFirst
df$errors<-D[s,]$errors
df$finalPay<-D[s,]$pay
df$cuM<-D[s,]$cuM_1
df$cuL<-D[s,]$cuL_1
df$precisionL<-D[s,]$precision_1
df$precisionM<-D[s,]$precision_2
df$similarity<-D[s,]$similarity
df$attnBoxL<-D[s,]$attnBox_1
df$attnBoxM<-D[s,]$attnBox_4
df$attnPayL<-D[s,]$attnPay_1
df$attnPayM<-D[s,]$attnPay_2
df$CR1<-D[s,]$CR1
df$CR2<-D[s,]$CR2
df$CR3<-D[s,]$CR3
df$strategy<-D[s,]$strategy
df$age<-D[s,]$age
df$sex<-D[s,]$sex
df$major<-D[s,]$major
df$math<-D[s,]$math
df$economics<-D[s,]$economics
df$comments<-D[s,]$comments
df<-df%>%
select(-clicks,-clickTimes)
if(length(S)>0){
S<-rbind(S,df)
}else{
S<-df
}
}
eutral benchmarks
View(S)
D
View(D)
D=read.csv(fp)
View(D)
D$dataSet
x=D$dataSet
x<-D[s,]$dataSet
x<-D[s,]$dataSet%>%
fromJSON()%>%
map_if(is.data.frame, list)%>%
as_tibble()
x<-D[s,]$dataSet%>%
fromJSON()%>%
map_if(is.data.frame, list)%>%
as_tibble()
#Code written by Ryan Oprea, edited by Uri SImonsohn
#2024 12 18
library('groundhog')
pkgs=c('this.path','magrittr','tibble','tidyverse','jsonlite')
date='2024-12-01'
groundhog.library(pkgs,date)
#Paths
RB=dirname(this.dir())
data_path=paste0(RB,"/data/")
other_path=paste0(RB,"/other/")
#datapaths
main = dirname(dirname(dirname(this.dir())))
data_path = paste0(main,"/Data/")
fp        = paste0(other_path,"error1_raw.csv")
D=read.csv(fp)
x=D$dataSet
# Clean
D<-D[-(1:2),] #Remove junk row
S<-data.frame()
# Remove any corrupted records
D$clength<-nchar(D$dataSet)
D<-D[D$clength<50000,]
s=1
x<-D[s,]$dataSet%>%
fromJSON()%>%
map_if(is.data.frame, list)%>%
as_tibble()
x
View(x)
df<-x
df$ID
df$ID<-D[s,]$ID
D[s,]$ID
D[s,]$aveFirst
D[s,]$errors
D[s,]
D[s,]$errors
x<-D[s,]$dataSet%>%
fromJSON()%>%
map_if(is.data.frame, list)%>%
as_tibble()
x
View(x)
D[s,]
D[1,]
alf=D[1,]
View(alf)
alf=D[1,]$errorLog
alf
fromJSON(alf)
fromJSON(D[2,]$errorLog)
fromJSON(D[2,]$errorLog)
fromJSON(alf)
fromJSON(D[2,]$errorLog)
fromJSON(D[4,]$errorLog)
lottery.A10=df$lottery[df$taskName=='A10']
lottery.A15=df$lottery[df$taskName=='A15']
mirror.A10=df$mirror[df$taskName=='A10']
mirror.A15=df$mirror[df$taskName=='A15']
par(mfrow=c(2,2))
hist2(lottery.A10,main="Lottery 50:50, lose $10, and gain $x, vs $0 for sure",xlab='$x chosen ')
#0 load the pkgs and set paths
#1 load  the data
#2 Function for plots
#2.1  hist2: histogram for discrete data
#2.2  hist3: Function to create histogram side-by-side lottery and complex elicitation
#3 Histograms for gains
#4 Histograms for losses
#5 Histograms for mixed gambles
#0 load the pkgs & data
library('groundhog')
pkgs=c('this.path')
date='2024-11-15'
groundhog.library(pkgs,date)
#GROUNDHOG NOTE:
# Groundhog loads the version of each package as current on the specified date.
# When re-running this code, you can change the date to a more recent one.
# Most likely the script will run fine with the new date, and it will load
# pkgs much faster if the date is recent. But, if the code does not run with
# a recent date, it means a pkg update broke this code. You can
# switch the date back to the one above. The older pkg versions will install
# faster if you run this code on the version of *R* available on that day.
# See details and instructions: https://groundhogr.com/many
#Paths
RB=dirname(this.dir())
data_path=paste0(RB,"/data/")
other_path=paste0(RB,"/other/")
# Paths are set dynamically based on location of this scripot
# assuming a ResearchBox folder structure:  RB/Code  RB/Data   RB/Other
#----------------------------------------------------------------------------------------
#1 load  the data
#From the posted code I run the script to produce the final dataset for repro
fp=file.path(data_path,'Oprea Data - manuscript.csv')
df = read.csv(fp)
#Load the errors csv
fp2=file.path(data_path,'Data with errors by participants - compiled by Uri.csv')
errors = read.csv(fp2)
#Merge them
#Rename treatmetn to avoid conflict
names(errors)[4]='treatment_errors'
#Actual merge
df2=merge(df, errors,by='ID',all=TRUE)
#Check coungs
nrow(df)
nrow(df2)  #gained 4 observations somehow, drop them
df2=df2[!is.na(df2$treatment),]
nrow(df2)  #gained 4 observations somehow, drop them
#Check treatments
table(df2$treatment,df2$treatment_errors)
#It has N=673 participants, matching the paper
length(unique(df$ID))
table(df$session)
table(df$treatment ,  df$session)
#Switch back to df
df=df2   #assign to df
rm(df2)  #remove df2
#Short variable names
lotteryG10 = df$lottery[df$taskName=='G10']
lotteryG25 = df$lottery[df$taskName=='G25']
lotteryG75 = df$lottery[df$taskName=='G75']
lotteryG90 = df$lottery[df$taskName=='G90']
lotteryL10 = df$lottery[df$taskName=='L10']
lotteryL25 = df$lottery[df$taskName=='L25']
lotteryL75 = df$lottery[df$taskName=='L75']
lotteryL90 = df$lottery[df$taskName=='L90']
mirrorG10 = df$mirror[df$taskName=='G10']
mirrorG25 = df$mirror[df$taskName=='G25']
mirrorG75 = df$mirror[df$taskName=='G75']
mirrorG90 = df$mirror[df$taskName=='G90']
mirrorL10 = df$mirror[df$taskName=='L10']
mirrorL25 = df$mirror[df$taskName=='L25']
mirrorL75 = df$mirror[df$taskName=='L75']
mirrorL90 = df$mirror[df$taskName=='L90']
#------------------------------------------------------
# Function for plots
#2 hist2: Neater histogram
hist2=function(x,col='dodgerblue',...)
{
xs <- seq(min(c(x,0)),max(c(x,25.5)),.5)
f <- table(factor(x, levels = xs))
f = f/sum(f)
ylim = range(f)
ylim[2]=ylim[2]*1.15
plot(xs,as.numeric(f),ylim=ylim,pch=16,cex=.1,...)
segments(x0=xs,x1=xs,y0=0,y1=f,lwd=4,col=col)
}
#2 hist3: Function to create histogram side-by-side lottery and complex elicitation
hist3=function(data=df,l,n,col1='red4',col2='dodgerblue',...)
{
df=data
#Get WTP
lottery = df$lottery[df$type==l & df$prob ==n]
mirror =  df$mirror[df$type==l & df$prob ==n]
wtp=c(lottery,mirror)
#Freq tables
xs <- seq(min(wtp),max(wtp),.5)
fl <- table(factor(lottery, levels = xs))
fm <- table(factor(mirror, levels = xs))
fl=fl/sum(fl)
fm=fm/sum(fm)
#ylim
fs=c(fl,fm)
ylim = range(fs)
ylim[2]=ylim[2] + .45*diff(ylim)
#Empty plot
plot(xs,as.numeric(fl),ylim=ylim,pch=16,cex=.1,ylab='% of participants',xlab='Certainty/Simplicity Equivalent',main=paste0(l,n),las=1,col='white')
#Vertical vars
segments(x0=xs-.1,x1=xs-.1,y0=0,y1=fl,lwd=4,col=col1)
segments(x0=xs+.1,x1=xs+.1,y0=0,y1=fm,lwd=4,col=col2)
#Line at EV
#abline(v=n/100*25,col='gray',lwd=3,lty=2)
outcome=ifelse(l=="G",25,-25)
points(n/100*outcome,ylim[2]*.75,pch=16,col='green4',cex=2)
text(x=n/100*outcome, ylim[2]*.75,paste0('EV=',n/100*25),pos=3,col='green4')
#Legend
ml=round(median(lottery),1)
mm=round(median(mirror),1)
legend('top',bty='n',col=c(col1,col2),lty=c(1,1),lwd=4,
legend=c(paste0("Lottery (Med = ",ml,")"),
paste0("Mirror (Med = ",mm,")")))
}
lottery.A10=df$lottery[df$taskName=='A10']
lottery.A15=df$lottery[df$taskName=='A15']
mirror.A10=df$mirror[df$taskName=='A10']
mirror.A15=df$mirror[df$taskName=='A15']
par(mfrow=c(2,2))
hist2(lottery.A10,main="Lottery 50:50, lose $10, and gain $x, vs $0 for sure",xlab='$x chosen ')
hist2(lottery.A15,main="Lottery 50:50, lose $15, and gain $x, vs $0 for sure",xlab='$x chosen ')
hist2(mirror.A10,main="For sure get mean(-$10 , $x) vs $0 for sure",xlab='$x chosen ')
hist2(mirror.A15,main="For sure get mean(-$15 , $x) vs $0 for sure",xlab='$x chosen ')
mean(lottery.A10<=0)
mean(lottery.A15<=0)
mean(mirror.A10<=0)
mean(mirror.A10<10)
mean(mirror.A10<9)
mean(mirror.A15<15)
mean(mirror.A15<=0)
lottery.G10=df$lottery[df$taskName=='G10']
lottery.G25=df$lottery[df$taskName=='G250']
mirror.G10=df$mirror[df$taskName=='G10']
mirror.G25=df$mirror[df$taskName=='G25']
mean(lottery.G10[mirror.G10==2.5])
mean(mirror.G10[lottery.G10==2.5])
library('groundhog')
pkgs=c('this.path','magrittr','tibble','tidyverse','jsonlite')
date='2024-12-01'
groundhog.library(pkgs,date)
#Paths
RB=dirname(this.dir())
data_path=paste0(RB,"/data/")
other_path=paste0(RB,"/other/")
#datapaths
main = dirname(dirname(dirname(this.dir())))
data_path = paste0(main,"/Data/")
fp        = paste0(other_path,"error1_raw.csv")
D=read.csv(fp)
# Clean
D<-D[-(1:2),] #Remove junk row
S<-data.frame()
# Remove any corrupted records
D$clength<-nchar(D$dataSet)
D<-D[D$clength<50000,]
s=1
x<-D[s,]$dataSet%>%
fromJSON()%>%
map_if(is.data.frame, list)%>%
as_tibble()
df<-x
D[1,]$attnBox_1
D[1,]$attnBox_2
D[1,]$attnBox_4
D[1,]$errorLog
fromJSOND[1,]$errorLog)
fromJSON[1,]$errorLog)
fromJSON(D[1,]$errorLog)
names(D[1,])
names(D[1,]$errors)
D[1,]$errors
